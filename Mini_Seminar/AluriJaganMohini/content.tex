%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% START ADDING TEXT HERE 
%
% Feel free to use \include commands to structure text in smaller
% pieces 
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Abstract gives a brief summary of the main points of a paper:
\begin{abstract}
In IoT system, To handle all the devices efficiently and to overcome the security issues, Software defined network(SDN) is incorporated into IoT. However, default routing protocols of SDN such as OSPF is vulnerable to the flow changes when the network is under attack. To overcome the above mentioned issue, Deep reinforcement learning based QoS-aware Secure routing Protocol (DQSP) is proposed in \cite{8935210}. 
\end{abstract}

\section{Introduction}
\label{sec:introduction}
\begin{itemize}
    \item Importance of SDN-IoT\cite{7939144}.
    \item Limitations of default routing protocols in SDN controller.
    \item Comparison of deep reinforcement learning and supervised learning methods \cite{8485853}.
    \item  Deep reinforcement learning based QoS-aware Secure routing Protocol(DQSP) in SDN-IoT.
\end{itemize}

\section{PROBLEM DEFINITION AND ATTACK MODELS}
\subsection{Network Model and Problem Definition}
\begin{itemize}
\item Packet forwarding process in traditional routing protocol. 
\item Limitations of traditional routing protocol.
\end{itemize}
\begin{itemize}
\item  Workflow of Deep reinforcement learning based QoS aware secure routing protocol (DQSP).
\begin{itemize}
\item Solution to achieve security and quality of service.
\end{itemize}
\end{itemize}

 \subsection{Attack Model}

  \cite{8935210} focuses on the two attacks which SDN-IoT system is susceptible to and they are:

 \begin{itemize}
  \item Gray hole attack. \cite{4449664}.
  \item Distributed denial of service (DDoS) attack.
\end{itemize}

\section{THE PROPOSED DQSP SCHEME}
\begin{itemize}
\item Architecture of DQSP.
\begin{itemize}
\item Describes the sensing layer, data layer, controller layer  and their functions followed by agent layer.
\end{itemize}
\item Related definitions of DQSP are stated in \cite{8935210} to enable optimized routing.
\item DQSP working algorithm is discussed in detail.
\begin{itemize}
\item DDPG is adopted to enable efficient secure routing.
\item DDPG follows the classic actor-critic model in reinforcement learning.
\item Working of Sampling algorithm . 
\item Working of DQSP Training algorithm.
\end{itemize}
\end{itemize}

\section {RESULTS AND PERFORMANCE EVALUATION}
\subsection{Experiment setup}
\begin{itemize}
\item Experiment is conducted by using tensor flow in the back end.
\item The training network of DQSP is built and in that training network, DDGP agent will be trained.
\item Finally, total rewards obtained in training process are updated.
\end{itemize}
\subsection{Performance Evaluation}
\begin{itemize}
\item {Performance of DQSP is evaluated with respect to the following metrics,}
\begin{itemize}
\item {Packet delivery ratio.}
\item{End-to-end delay.}
\end{itemize}
\item Results are compared against the state-of-art routing protocol OSPF.
\end{itemize}


\section{Conclusion}
As per experimental results.

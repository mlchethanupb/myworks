{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import w_mac\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import w_mac\n",
    "from collections import defaultdict\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "\n",
    "# data = [(0,2),(0,1),(1,2),(2,3),(2,4),(3,4)]\n",
    "#data = [(0,1),(0,8),(0,7),(0,12),(0,2),(1,2),(1,12),(1,5),(1,6),(1,14),(1,7),(1,8),(5,6),(5,14),(6,14),(8,7),(12,2),(2,3),(2,4),(4,13),(4,9),(4,11),(4,10),(10,11),(9,13),(3,4),(9,10),(9,11),(5,15)]\n",
    "d = defaultdict(list)\n",
    "data = [(0,2),(0,1),(0,3),(1,2),(1,3),(2,3),(2,4),(3,4),(5,2),(5,3),(5,4)]\n",
    "# defaultdict(<type 'list'>, {})\n",
    "for node, dest in data:\n",
    "    d[node].append(dest)\n",
    "print(d)\n",
    "\n",
    "G = nx.Graph()\n",
    "for k,v in d.items():\n",
    "    for vv in v:\n",
    "        G.add_edge(k,vv)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess environment\n",
    "#env = make_vec_env('wmac-v0', n_envs=4)\n",
    "#env = gym.make('wmac-v0')\n",
    "\n",
    "env = gym.make('wmac-graph-v0',graph=G)\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2(MlpPolicy, env, verbose=1, tensorboard_log=\"./ppo2_tensorboard/\")\n",
    "model.learn(total_timesteps=250000)\n",
    "model.save(\"ppo2_wmac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO2.load(\"ppo2_wmac\")\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "    #env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

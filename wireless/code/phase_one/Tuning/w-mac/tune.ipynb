{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import w_mac\n",
    "from collections import defaultdict\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "import dill\n",
    "from ray import tune\n",
    "from ray.tune.suggest.ax import AxSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import dill\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from ax.service.ax_client import AxClient\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import report\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "# from flowsim.environment.network import Network\n",
    "# from flowsim.environment.hopcount_env import HopCountEnv\n",
    "# from flowsim.environment.delay_env import NetworkDelayEnv\n",
    "# from flowsim.tuning.monitor import OptimizationCallback\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "# from stable_baselines.common.monitor import Monitor\n",
    "from stable_baselines.common.callbacks import EveryNTimesteps\n",
    "from w_mac.envs.w_mac_env import W_MAC_Env\n",
    "# from w_mac.envs.monitor import OptimizationCallback\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('wmac-tune-v0') #env without passing graph\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(dill.pickles(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error - TypeError: __init__() takes 1 positional argument but 2 were given\n",
    "\n",
    "\n",
    "# config = {\n",
    "#     \"env\": deepcopy(W_MAC_Env),\n",
    "#     \"num_workers\": 2,\n",
    "#     # \"vf_share_layers\": tune.grid_search([True, False]),\n",
    "#     \"lr\": tune.grid_search([1e-4, 1e-5, 1e-6]),\n",
    "#     }\n",
    "# register_env(\"testenv\", lambda config: TestEnv(config)\n",
    "\n",
    "# results = tune.run(\n",
    "#     'A2C', \n",
    "#     stop={\n",
    "#         'timesteps_total': 100000\n",
    "#     },\n",
    "#     config=config)\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "register_env(\"wmac-tune-v0\", lambda config: W_MAC_Env)\n",
    "tune.run(\n",
    "    \"A2C\",\n",
    "    config={\n",
    "        \"env\": 'wmac-tune-v0'\n",
    "        # \"num_workers\": 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-19 16:07:27,794\tERROR worker.py:643 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 3.8/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (2 PENDING, 1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">1e-05 </td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">1e-06 </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16378 tid 16378 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16376 tid 16376 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16379 tid 16379 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m 2020-10-19 16:07:42,648\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16378)\u001b[0m 2020-10-19 16:07:42,648\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m 2020-10-19 16:07:42,655\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16376)\u001b[0m 2020-10-19 16:07:42,658\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m 2020-10-19 16:07:42,721\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16379)\u001b[0m 2020-10-19 16:07:42,721\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-10-19 16:07:42,981\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_6b8d6_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::A2C.train()\u001b[39m (pid=16378, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"<ipython-input-22-609625dde2e9>\", line 2, in <lambda>\n",
      "TypeError: __init__() takes 1 positional argument but 2 were given\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 4.4/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (1 ERROR, 2 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">1e-05 </td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">1e-06 </td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00000</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_6b8d6_00000_0_lr=0.0001_2020-10-19_16-07-27/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-19 16:07:42,998\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_6b8d6_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::A2C.train()\u001b[39m (pid=16376, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"<ipython-input-22-609625dde2e9>\", line 2, in <lambda>\n",
      "TypeError: __init__() takes 1 positional argument but 2 were given\n",
      "2020-10-19 16:07:43,207\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe8381c0d01000000.\n",
      "2020-10-19 16:07:43,219\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffc9a5fb4f01000000.\n",
      "2020-10-19 16:07:43,271\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffb71cdd5b01000000.\n",
      "2020-10-19 16:07:43,276\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_6b8d6_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::A2C.train()\u001b[39m (pid=16379, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"<ipython-input-22-609625dde2e9>\", line 2, in <lambda>\n",
      "TypeError: __init__() takes 1 positional argument but 2 were given\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 3.7/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (3 ERROR)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">1e-05 </td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00002</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">1e-06 </td></tr>\n</tbody>\n</table><br>Number of errored trials: 3<br><table>\n<thead>\n<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00000</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_6b8d6_00000_0_lr=0.0001_2020-10-19_16-07-27/error.txt</td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00001</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_6b8d6_00001_1_lr=1e-05_2020-10-19_16-07-27/error.txt </td></tr>\n<tr><td>A2C_wmac-tune-v0_6b8d6_00002</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_6b8d6_00002_2_lr=1e-06_2020-10-19_16-07-27/error.txt </td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-19 16:07:43,305\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff7b1aa08a01000000.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [A2C_wmac-tune-v0_6b8d6_00000, A2C_wmac-tune-v0_6b8d6_00001, A2C_wmac-tune-v0_6b8d6_00002])",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-609625dde2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [A2C_wmac-tune-v0_6b8d6_00000, A2C_wmac-tune-v0_6b8d6_00001, A2C_wmac-tune-v0_6b8d6_00002])"
     ]
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)\n",
    "register_env(\"wmac-tune-v0\", lambda config: W_MAC_Env(config))\n",
    "config = {\n",
    "    \"env\": 'wmac-tune-v0',\n",
    "    # \"num_workers\": 2,\n",
    "    # \"vf_share_layers\": tune.grid_search([True, False]),\n",
    "    \"lr\": tune.grid_search([1e-4, 1e-5, 1e-6]),\n",
    "    }\n",
    "\n",
    "stop = {'timesteps_total': 10000\n",
    "}\n",
    "results = tune.run(\n",
    "    'A2C', \n",
    "    \n",
    "    config=config,\n",
    "    stop = stop\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.pickles(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAY_TUNE_SAMPLES = 48\n",
    "EVAL_EPISODES = 5\n",
    "TOTAL_TIMESTEPS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = W_MAC_Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-19 16:06:26,743\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 3.4/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (2 PENDING, 1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_4891d_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.01  </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m WARNING:tensorflow:From /home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16372 tid 16372 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16373 tid 16373 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"core\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"socket\".\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #191: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 \n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m OMP: Info #252: KMP_AFFINITY: pid 16374 tid 16374 thread 0 bound to OS proc set 0\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m 2020-10-19 16:06:53,540\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16372)\u001b[0m 2020-10-19 16:06:53,541\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m 2020-10-19 16:06:53,553\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16373)\u001b[0m 2020-10-19 16:06:53,553\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-10-19 16:06:53,919\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_4891d_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(UnregisteredEnv): \u001b[36mray::A2C.train()\u001b[39m (pid=16373, ip=131.234.29.24)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 121, in spec\n",
      "    return self.env_specs[id]\n",
      "KeyError: 'wmac-tune-v0'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::A2C.train()\u001b[39m (pid=16373, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 570, in <lambda>\n",
      "    lambda env_config: gym.make(env, **env_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 145, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 89, in make\n",
      "    spec = self.spec(path)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 131, in spec\n",
      "    raise error.UnregisteredEnv('No registered env with id: {}'.format(id))\n",
      "gym.error.UnregisteredEnv: No registered env with id: wmac-tune-v0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 4.6/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (1 ERROR, 2 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_4891d_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.01  </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                       </th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_4891d_00001</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_4891d_00001_1_lr=0.001_2020-10-19_16-06-29/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-19 16:06:53,950\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_4891d_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(UnregisteredEnv): \u001b[36mray::A2C.train()\u001b[39m (pid=16372, ip=131.234.29.24)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 121, in spec\n",
      "    return self.env_specs[id]\n",
      "KeyError: 'wmac-tune-v0'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::A2C.train()\u001b[39m (pid=16372, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 570, in <lambda>\n",
      "    lambda env_config: gym.make(env, **env_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 145, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 89, in make\n",
      "    spec = self.spec(path)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 131, in spec\n",
      "    raise error.UnregisteredEnv('No registered env with id: {}'.format(id))\n",
      "gym.error.UnregisteredEnv: No registered env with id: wmac-tune-v0\n",
      "2020-10-19 16:06:54,097\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff642d566b01000000.\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m 2020-10-19 16:06:54,088\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=16374)\u001b[0m 2020-10-19 16:06:54,089\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-10-19 16:06:54,118\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd5bc8eee01000000.\n",
      "2020-10-19 16:06:54,139\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd61624ee01000000.\n",
      "2020-10-19 16:06:54,160\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4d92074001000000.\n",
      "2020-10-19 16:06:54,299\tERROR trial_runner.py:567 -- Trial A2C_wmac-tune-v0_4891d_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(UnregisteredEnv): \u001b[36mray::A2C.train()\u001b[39m (pid=16374, ip=131.234.29.24)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 121, in spec\n",
      "    return self.env_specs[id]\n",
      "KeyError: 'wmac-tune-v0'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::A2C.train()\u001b[39m (pid=16374, ip=131.234.29.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 125, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 699, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 74, in __init__\n",
      "    self._local_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 305, in _make_worker\n",
      "    extra_python_environs=extra_python_environs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 332, in __init__\n",
      "    self.env = _validate_env(env_creator(env_context))\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 570, in <lambda>\n",
      "    lambda env_config: gym.make(env, **env_config)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 145, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 89, in make\n",
      "    spec = self.spec(path)\n",
      "  File \"/home/aicon/anaconda3/envs/wireless/lib/python3.7/site-packages/gym/envs/registration.py\", line 131, in spec\n",
      "    raise error.UnregisteredEnv('No registered env with id: {}'.format(id))\n",
      "gym.error.UnregisteredEnv: No registered env with id: wmac-tune-v0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 4.0/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/16.94 GiB heap, 0.0/5.81 GiB objects<br>Result logdir: /home/aicon/ray_results/A2C<br>Number of trials: 3 (3 ERROR)<br><table>\n<thead>\n<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_4891d_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.01  </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00002</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n</tbody>\n</table><br>Number of errored trials: 3<br><table>\n<thead>\n<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n</thead>\n<tbody>\n<tr><td>A2C_wmac-tune-v0_4891d_00000</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_4891d_00000_0_lr=0.01_2020-10-19_16-06-29/error.txt  </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00001</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_4891d_00001_1_lr=0.001_2020-10-19_16-06-29/error.txt </td></tr>\n<tr><td>A2C_wmac-tune-v0_4891d_00002</td><td style=\"text-align: right;\">           1</td><td>/home/aicon/ray_results/A2C/A2C_wmac-tune-v0_4891d_00002_2_lr=0.0001_2020-10-19_16-06-29/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [A2C_wmac-tune-v0_4891d_00000, A2C_wmac-tune-v0_4891d_00001, A2C_wmac-tune-v0_4891d_00002])",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5ffaf32564a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"num_gpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# \"num_workers\": 1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     },)\n",
      "\u001b[0;32m~/anaconda3/envs/wireless/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [A2C_wmac-tune-v0_4891d_00000, A2C_wmac-tune-v0_4891d_00001, A2C_wmac-tune-v0_4891d_00002])"
     ]
    }
   ],
   "source": [
    "# haitham's example, unregister env error\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "tune.run(\n",
    "    \"A2C\",\n",
    "    stop={\"episode_reward_mean\": 200},\n",
    "    config={\n",
    "        \"env\": 'wmac-tune-v0',\n",
    "        \"num_gpus\": 0,\n",
    "        # \"num_workers\": 1,\n",
    "        \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    },)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without search agent, pickling error\n",
    "def evaluate_objective(config):\n",
    "    tune_env = deepcopy(model)\n",
    "    \n",
    "    tune_agent = A2C(\"MlpPolicy\", tune_env, **config)\n",
    "    tune_agent.learn(total_timesteps=1000)\n",
    "    episode_rewards, episode_lengths = evaluate_policy(tune_agent, tune_env,\n",
    "                                                           5,\n",
    "                                                           render=False,\n",
    "                                                           deterministic=deterministic,\n",
    "                                                           return_episode_rewards=True)\n",
    "    episode_reward_mean, std_reward = np.mean(\n",
    "            episode_rewards), np.std(episode_rewards)\n",
    "    mean_ep_length, std_ep_length = np.mean(\n",
    "            episode_lengths), np.std(episode_lengths)\n",
    "    \n",
    "    tune.report(episode_reward_mean=episode_reward_mean,\n",
    "            std_reward=std_reward,\n",
    "            mean_ep_length=mean_ep_length,\n",
    "            std_ep_length=std_ep_length)\n",
    "\n",
    "analysis = tune.run(evaluate_objective, metric='episode_reward_mean', mode='max')\n",
    "best_trial = analysis.best_trial\n",
    "best_config = analysis.best_config\n",
    "print(best_trial, best_config)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register env and tune run\n",
    "tune.register_trainable(\"wmac-tune-v0\", w_mac.envs.w_mac_env.W_MAC_Env)\n",
    "ray.init()\n",
    "\n",
    "tune.run_experiments({\n",
    "    \"my_experiment\": {\n",
    "        \"run\": 'wmac-tune-v0',\n",
    "        \"stop\": { \"mean_accuracy\": 100 },\n",
    "        \"config\": {\n",
    "            \"alpha\": tune.grid_search([0.2, 0.4, 0.6]),\n",
    "            \"beta\": tune.grid_search([1, 2]),\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}